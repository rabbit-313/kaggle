{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed1ed64",
   "metadata": {},
   "source": [
    "## カラムの日本語訳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6542b9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T10:54:30.415651Z",
     "iopub.status.busy": "2024-05-08T10:54:30.415328Z",
     "iopub.status.idle": "2024-05-08T10:54:30.419886Z",
     "shell.execute_reply": "2024-05-08T10:54:30.419060Z"
    },
    "papermill": {
     "duration": 0.013328,
     "end_time": "2024-05-08T10:54:30.421788",
     "exception": false,
     "start_time": "2024-05-08T10:54:30.408460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MonsoonIntensity - モンスーンの強度\n",
    "# TopographyDrainage - 地形排水\n",
    "# RiverManagement - 河川管理\n",
    "# Deforestation - 森林破壊\n",
    "# Urbanization - 都市化\n",
    "# ClimateChange - 気候変動\n",
    "# DamsQuality - ダムの品質\n",
    "# Siltation - 堆積\n",
    "# AgriculturalPractices - 農業の慣行\n",
    "# Encroachments - 侵害\n",
    "# IneffectiveDisasterPreparedness - 効果のない災害対策\n",
    "# DrainageSystems - 排水システム\n",
    "# CoastalVulnerability - 沿岸の脆弱性\n",
    "# Landslides - 地滑り\n",
    "# Watersheds - 流域\n",
    "# DeterioratingInfrastructure - 低下するインフラ\n",
    "# PopulationScore - 人口スコア\n",
    "# WetlandLoss - 湿地の喪失\n",
    "# InadequatePlanning - 不十分な計画\n",
    "# PoliticalFactors - 政治的要因\n",
    "# FloodProbability - 洪水確率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe015b3",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d9adfdd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-08T10:54:16.247315Z",
     "iopub.status.busy": "2024-05-08T10:54:16.246563Z",
     "iopub.status.idle": "2024-05-08T10:54:27.011059Z",
     "shell.execute_reply": "2024-05-08T10:54:27.010250Z"
    },
    "papermill": {
     "duration": 10.77434,
     "end_time": "2024-05-08T10:54:27.013578",
     "exception": false,
     "start_time": "2024-05-08T10:54:16.239238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e77d5",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c877c004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T10:54:27.029731Z",
     "iopub.status.busy": "2024-05-08T10:54:27.028732Z",
     "iopub.status.idle": "2024-05-08T10:54:30.239751Z",
     "shell.execute_reply": "2024-05-08T10:54:30.238778Z"
    },
    "papermill": {
     "duration": 3.221399,
     "end_time": "2024-05-08T10:54:30.242250",
     "exception": false,
     "start_time": "2024-05-08T10:54:27.020851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"inputs/train.csv\")\n",
    "test = pd.read_csv(\"inputs/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3317fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T10:54:30.301512Z",
     "iopub.status.busy": "2024-05-08T10:54:30.301166Z",
     "iopub.status.idle": "2024-05-08T10:54:30.400020Z",
     "shell.execute_reply": "2024-05-08T10:54:30.399224Z"
    },
    "papermill": {
     "duration": 0.108057,
     "end_time": "2024-05-08T10:54:30.402384",
     "exception": false,
     "start_time": "2024-05-08T10:54:30.294327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=[\"FloodProbability\", \"id\"], axis=1)\n",
    "y_train = train[\"FloodProbability\"]\n",
    "x_test = test.drop(columns=[\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8def42",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abae9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計データの追加\n",
    "def cleaning(dataset):\n",
    "    features = dataset.columns.tolist()\n",
    "    dataset['total'] = dataset[features].sum(axis=1)\n",
    "    dataset['mean_features'] = 0.1*dataset[features].mean(axis=1)\n",
    "    dataset['std_features'] = dataset[features].std(axis=1)\n",
    "    dataset['max_features'] = dataset[features].max(axis=1)\n",
    "    dataset['min_features'] = dataset[features].min(axis=1)\n",
    "    dataset['median_features'] = 0.1*dataset[features].median(axis=1)\n",
    "    dataset['ptp'] = dataset[features].values.ptp(axis=1)\n",
    "    dataset['q25'] = dataset[features].quantile(0.25, axis=1)\n",
    "    dataset['q75'] = dataset[features].quantile(0.75, axis=1)\n",
    "\n",
    "cleaning(x_train)\n",
    "cleaning(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244c5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の追加\n",
    "def add_features(df):\n",
    "    df['ClimateImpact'] = df['MonsoonIntensity'] + df['ClimateChange']\n",
    "    df['AnthropogenicPressure'] = df['Deforestation'] + df['Urbanization'] + df['AgriculturalPractices'] + df['Encroachments']\n",
    "    df['InfrastructureQuality'] = df['DamsQuality'] + df['DrainageSystems'] + df['DeterioratingInfrastructure']\n",
    "    df['CoastalVulnerabilityTotal'] = df['CoastalVulnerability'] + df['Landslides']\n",
    "    df['PreventiveMeasuresEfficiency'] = df['RiverManagement'] + df['IneffectiveDisasterPreparedness'] + df['InadequatePlanning']\n",
    "    df['EcosystemImpact'] = df['WetlandLoss'] + df['Watersheds']\n",
    "    df['SocioPoliticalContext'] = df['PopulationScore'] * df['PoliticalFactors']\n",
    "\n",
    "add_features(x_train)\n",
    "add_features(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f090a9c",
   "metadata": {},
   "source": [
    "## trainとtestの分布を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d8f993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T10:54:30.516159Z",
     "iopub.status.busy": "2024-05-08T10:54:30.515904Z",
     "iopub.status.idle": "2024-05-08T10:54:30.520387Z",
     "shell.execute_reply": "2024-05-08T10:54:30.519599Z"
    },
    "papermill": {
     "duration": 0.013126,
     "end_time": "2024-05-08T10:54:30.522206",
     "exception": false,
     "start_time": "2024-05-08T10:54:30.509080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_distribution_pairs(train, test, feature, hue=\"set\", palette=None):\n",
    "#     data_df = train.copy()\n",
    "#     data_df['set'] = 'train'\n",
    "#     data_df = pd.concat([data_df, test.copy()]).fillna('test')\n",
    "#     data_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "#     f, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "#     for i, s in enumerate(data_df[hue].unique()):\n",
    "#         selection = data_df.loc[data_df[hue]==s, feature]\n",
    "#         # Filter 'selection' to include only the central 95% of the data\n",
    "#         q_025, q_975 = np.percentile(selection, [2.5, 97.5])\n",
    "#         selection_filtered = selection[(selection >= q_025) & (selection <= q_975)]\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "#             sns.histplot(selection_filtered, color=palette[i], ax=axes[0], label=s)\n",
    "#             sns.boxplot(x=hue, y=feature, data=data_df, palette=palette, ax=axes[1])\n",
    "#     axes[0].set_title(f\"Paired train/test distributions of {feature}\")\n",
    "#     axes[1].set_title(f\"Paired train/test boxplots of {feature}\")\n",
    "#     axes[0].legend()\n",
    "#     axes[1].legend()\n",
    "#     plt.show()\n",
    "# color_list = [\"#A5D7E8\", \"#576CBC\", \"#19376D\", \"#0B2447\"]\n",
    "# for feature in x_train.columns:\n",
    "#   plot_distribution_pairs(x_train, x_test, feature, palette=color_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6d1f",
   "metadata": {},
   "source": [
    "## stackingによるアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d404abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, x_train, y_train, x_test):\n",
    "    preds = list()\n",
    "    preds_test = list()\n",
    "    va_idxes = list()\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "    iterator = tqdm(enumerate(kf.split(x_train)), total=kf.get_n_splits(), desc='CV Progress')  # tqdmを使ってプログレスバーを表示\n",
    "    \n",
    "    for _, (tr_idx, va_idx) in iterator:\n",
    "        tr_x, va_x = x_train.iloc[tr_idx], x_train.iloc[va_idx]\n",
    "        tr_y, va_y = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "        \n",
    "        model.fit(tr_x, tr_y)\n",
    "        \n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        \n",
    "        pred_test = model.predict(x_test)\n",
    "        preds_test.append(pred_test)\n",
    "        \n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6267262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model_1 = lgb.LGBMRegressor(max_depth=5, n_estimators=100, random_state=42, device=\"gpu\")\n",
    "lgb_model_2 = lgb.LGBMRegressor(max_depth=7, n_estimators=100, random_state=42, device=\"gpu\")\n",
    "lgb_model_3 = lgb.LGBMRegressor(max_depth=10, n_estimators=100, random_state=42, device=\"gpu\")\n",
    "\n",
    "rf_model_1 = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=42)\n",
    "rf_model_2 = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=42)\n",
    "\n",
    "mlp_1_layer = MLPRegressor(hidden_layer_sizes=(50,), max_iter=500, random_state=42)\n",
    "mlp_2_layers = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=500, random_state=42)\n",
    "\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "469602be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.041061 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504459\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  20%|██        | 1/5 [00:03<00:12,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.038766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504457\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  40%|████      | 2/5 [00:06<00:09,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.039165 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  60%|██████    | 3/5 [00:09<00:06,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1101\n",
      "[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.039253 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504490\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  80%|████████  | 4/5 [00:12<00:03,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.039218 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504495\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress: 100%|██████████| 5/5 [00:15<00:00,  3.05s/it]\n",
      "CV Progress: 100%|██████████| 5/5 [16:19<00:00, 195.89s/it]\n",
      "CV Progress: 100%|██████████| 5/5 [03:50<00:00, 46.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM: 0.8687478072941155\n",
      "Random Forest: 0.8642661416782262\n",
      "MLP: 0.5438519181996369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train_lgb_2, pred_test_lgb_2 = predict_cv(lgb_model_2, x_train, y_train, x_test)\n",
    "pred_train_rf_1, pred_test_rf_1 = predict_cv(rf_model_1, x_train, y_train, x_test)\n",
    "pred_train_lgb_1, pred_test_lgb_1 = predict_cv(mlp_1_layer, x_train, y_train, x_test)\n",
    "\n",
    "print(f\"LGBM: {r2_score(y_train, pred_train_lgb_2)}\")\n",
    "print(f\"Random Forest: {r2_score(y_train, pred_train_rf_1)}\")\n",
    "print(f\"MLP: {r2_score(y_train, pred_train_lgb_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd9b9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.062817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504459\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  20%|██        | 1/5 [00:33<02:14, 33.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.062789 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504457\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  40%|████      | 2/5 [01:07<01:40, 33.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.062838 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504501\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  60%|██████    | 3/5 [01:40<01:07, 33.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1101\n",
      "[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.062969 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504490\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:  80%|████████  | 4/5 [02:14<00:33, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA TITAN RTX, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 36 dense feature groups (30.71 MB) transferred to GPU in 0.064211 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.504495\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress: 100%|██████████| 5/5 [02:47<00:00, 33.55s/it]\n",
      "CV Progress: 100%|██████████| 5/5 [26:32<00:00, 318.46s/it]\n",
      "CV Progress: 100%|██████████| 5/5 [30:03<00:00, 360.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_1: 0.8687668574621917\n",
      "lgb_2: 0.8689157473042654\n",
      "lgb_3: 0.8687668574621917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train_lgb_3, pred_test_lgb_3 = predict_cv(lgb_model_3, x_train, y_train, x_test)\n",
    "pred_train_mlp_2, pred_test_mlp_2 = predict_cv(mlp_2_layers, x_train, y_train, x_test)\n",
    "pred_train_rf_2, pred_test_rf_2 = predict_cv(rf_model_2, x_train, y_train, x_test)\n",
    "\n",
    "print(f\"lgb_1: {r2_score(y_train, pred_train_lgb_3)}\")\n",
    "print(f\"lgb_2: {r2_score(y_train, pred_train_rf_2)}\")\n",
    "print(f\"lgb_3: {r2_score(y_train, pred_train_lgb_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "787d2302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1117957, 6) (745305, 6)\n"
     ]
    }
   ],
   "source": [
    "x2_train = pd.DataFrame({'lgb_3': pred_train_lgb_3, 'lgb_2': pred_train_lgb_2, 'rf_1': pred_train_rf_1, 'rf_2': pred_train_rf_2, 'mlp_1': pred_train_lgb_1, 'mlp_2': pred_train_mlp_2})\n",
    "x2_test = pd.DataFrame({'lgb_3': pred_test_lgb_3, 'lgb_2': pred_test_lgb_2, 'rf_1': pred_test_rf_1, 'rf_2': pred_test_rf_2, 'mlp_1': pred_test_lgb_1, 'mlp_2': pred_test_mlp_2})\n",
    "print(x2_train.shape, x2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed4202a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress: 100%|██████████| 5/5 [00:00<00:00,  8.71it/s]\n",
      "CV Progress: 100%|██████████| 5/5 [00:00<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: 0.869016602673978\n",
      "Ridge: 0.8690034185266192\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "ridge_model = Ridge()\n",
    "pred_train_linear, pred_test_linear = predict_cv(linear_model, x2_train, y_train, x2_test)\n",
    "pred_train_ridge, pred_test_ridge = predict_cv(ridge_model, x2_train, y_train, x2_test)\n",
    "\n",
    "print(f\"Linear: {r2_score(y_train, pred_train_linear)}\")\n",
    "print(f\"Ridge: {r2_score(y_train, pred_train_ridge)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd2dd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_train = pd.DataFrame({'linear': pred_train_linear, 'ridge': pred_train_ridge})\n",
    "x3_test = pd.DataFrame({'linear': pred_test_linear, 'ridge': pred_test_ridge})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e0c5f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress: 100%|██████████| 5/5 [00:00<00:00, 21.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last: 0.8690154564476442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "last_model = LinearRegression()\n",
    "# last_model = Ridge()\n",
    "pred_train_last, pred_test_last = predict_cv(last_model, x3_train, y_train, x3_test)\n",
    "print(f\"last: {r2_score(y_train, pred_train_last)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73689a0d",
   "metadata": {},
   "source": [
    "## 重要ではない特徴量を取り除いて再訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585347fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# min = 2000\n",
    "# feature_idx = list()\n",
    "# for idx, item in enumerate(model.feature_importances_):\n",
    "#     if item <= min:\n",
    "#         feature_idx.append(idx)\n",
    "# feature_name = x_train.columns\n",
    "\n",
    "# x_train = x_train.drop(columns=list(feature_name[feature_idx]), axis=1)\n",
    "# x_test = x_test.drop(columns=list(feature_name[feature_idx]), axis=1)\n",
    "# model = LGBMRegressor(**study.best_params, objective='regression', random_state=0, device='gpu', verbosity=-1)\n",
    "# cv = KFold(5, shuffle=True, random_state=0)\n",
    "# cv_splits = cv.split(x_train, y_train)\n",
    "# scores = []\n",
    "# for train_idx, val_idx in cv_splits:\n",
    "#     x_train_fold, x_val_fold = x_train.iloc[train_idx], x_train.iloc[val_idx]\n",
    "#     y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "#     model.fit(x_train_fold, y_train_fold)\n",
    "#     y_pred = model.predict(x_val_fold)\n",
    "#     r2 = r2_score(y_val_fold, y_pred)\n",
    "#     print(f'score: {r2}')\n",
    "#     scores.append(r2)\n",
    "\n",
    "# print(f\"Mean Score ＝ {np.mean(scores):.5f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432bbe45",
   "metadata": {},
   "source": [
    "## 提出用ファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9126847d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:06:07.496306Z",
     "iopub.status.busy": "2024-05-08T11:06:07.495989Z",
     "iopub.status.idle": "2024-05-08T11:07:47.527333Z",
     "shell.execute_reply": "2024-05-08T11:07:47.526303Z"
    },
    "papermill": {
     "duration": 100.043481,
     "end_time": "2024-05-08T11:07:47.529702",
     "exception": false,
     "start_time": "2024-05-08T11:06:07.486221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.577747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.455502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.449118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.466489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  FloodProbability\n",
       "0  1117957          0.577747\n",
       "1  1117958          0.455502\n",
       "2  1117959          0.449118\n",
       "3  1117960          0.466400\n",
       "4  1117961          0.466489"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(\"inputs/sample_submission.csv\")\n",
    "submit[\"FloodProbability\"] = pred_test_last\n",
    "submit.to_csv(\"outputs/submission_stacking.csv\", index=False)\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8121328,
     "sourceId": 73278,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 816.592185,
   "end_time": "2024-05-08T11:07:50.065702",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-08T10:54:13.473517",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
